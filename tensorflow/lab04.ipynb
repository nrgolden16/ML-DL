{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and label\n",
    "x1=[73.,93.,89.,96.,73.]\n",
    "x2=[80.,88.,91.,98.,66.]\n",
    "x3=[152.,185.,180.,196.,142.]\n",
    "\n",
    "# weights\n",
    "w1= tf.Variable(10.)\n",
    "w2= tf.Variable(10.)\n",
    "w3= tf.Variable(10.)\n",
    "b=tf.Variable(10.)\n",
    "\n",
    "hypothesis = w1 * x1 + w2 * x2 + w3 * x3 +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3060., 3670., 3610., 3910., 2820.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   54209.3828\n",
      "   50 |    2725.5527\n",
      "  100 |     143.8439\n",
      "  150 |      14.3785\n",
      "  200 |       7.8841\n",
      "  250 |       7.5560\n",
      "  300 |       7.5372\n",
      "  350 |       7.5338\n",
      "  400 |       7.5312\n",
      "  450 |       7.5286\n",
      "  500 |       7.5261\n",
      "  550 |       7.5235\n",
      "  600 |       7.5210\n",
      "  650 |       7.5184\n",
      "  700 |       7.5158\n",
      "  750 |       7.5133\n",
      "  800 |       7.5108\n",
      "  850 |       7.5082\n",
      "  900 |       7.5057\n",
      "  950 |       7.5031\n",
      " 1000 |       7.5006\n"
     ]
    }
   ],
   "source": [
    "#data and label\n",
    "x1=[73.,93.,89.,96.,73.]\n",
    "x2=[80.,88.,91.,98.,66.]\n",
    "x3=[75.,93.,90.,100.,70.]\n",
    "Y=[152.,185.,180.,196.,142.]\n",
    "\n",
    "#random weights\n",
    "w1=tf.Variable(tf.random.normal([1]))\n",
    "w2=tf.Variable(tf.random.normal([1]))\n",
    "w3=tf.Variable(tf.random.normal([1]))\n",
    "b=tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    #tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:   #with as 키워드\n",
    "        hypothesis = w1 * x1 + w2 * w2 + w3 * x3 +b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y)) #reduce_mean : 모든 차원이 제거되고 평균을 구함\n",
    "    #calcualtes the gradients fo the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1,w2,w3,b])\n",
    "    \n",
    "    \n",
    "    #update w1,w2,w3,and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 ==0 :\n",
    "        print(\"{:5} | {:12.4f}\".format(i,cost.numpy()))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.GradientTape()\n",
    "\n",
    "(1000+1)\n",
    "\n",
    "손실함수가 최소가 되는 w를 찾는 건 알겠는데 그럼 미분할 때 w는 이미 값이 주어졌는데 어떻게 미분하지 미분할때는 대입하지 않고 미분한다음 대입하고 w에 학습률을 주어서 할당한 다음 로스를 구할 때 대입하나?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.GradientTape()\n",
    "\n",
    "텐서플로는 자동 미분(주어진 입력 변수에 대한 연산의 그래디언트(gradient)를 계산하는 것)을 위한 tf.GradientTape API를 제공합니다. tf.GradientTape는 컨텍스트(context) 안에서 실행된 모든 연산을 테이프(tape)에 \"기록\"합니다. 그 다음 텐서플로는 후진 방식 자동 미분(reverse mode differentiation)을 사용해 테이프에 \"기록된\" 연산의 그래디언트를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 61173.2891\n",
      "   50 |   681.2703\n",
      "  100 |    10.0446\n",
      "  150 |     2.5937\n",
      "  200 |     2.5080\n",
      "  250 |     2.5041\n",
      "  300 |     2.5011\n",
      "  350 |     2.4981\n",
      "  400 |     2.4951\n",
      "  450 |     2.4921\n",
      "  500 |     2.4892\n",
      "  550 |     2.4862\n",
      "  600 |     2.4832\n",
      "  650 |     2.4803\n",
      "  700 |     2.4774\n",
      "  750 |     2.4744\n",
      "  800 |     2.4715\n",
      "  850 |     2.4686\n",
      "  900 |     2.4657\n",
      "  950 |     2.4628\n",
      " 1000 |     2.4599\n",
      " 1050 |     2.4571\n",
      " 1100 |     2.4542\n",
      " 1150 |     2.4513\n",
      " 1200 |     2.4484\n",
      " 1250 |     2.4456\n",
      " 1300 |     2.4427\n",
      " 1350 |     2.4399\n",
      " 1400 |     2.4371\n",
      " 1450 |     2.4343\n",
      " 1500 |     2.4314\n",
      " 1550 |     2.4286\n",
      " 1600 |     2.4258\n",
      " 1650 |     2.4230\n",
      " 1700 |     2.4202\n",
      " 1750 |     2.4174\n",
      " 1800 |     2.4146\n",
      " 1850 |     2.4118\n",
      " 1900 |     2.4091\n",
      " 1950 |     2.4063\n",
      " 2000 |     2.4035\n"
     ]
    }
   ],
   "source": [
    "data=np.array([\n",
    "# x1, x2, x3, y\n",
    "[73., 80.,  75., 152.],\n",
    "[93., 88.,  93., 185.],\n",
    "[89., 91.,  90., 180.],\n",
    "[96., 98., 100., 196.],\n",
    "[73., 66.,  70., 142.]\n",
    "],dtype=np.float32)\n",
    "\n",
    "X=data[:,:-1]\n",
    "y=data[:,[-1]]\n",
    "\n",
    "W=tf.Variable(tf.random.normal([3,1])) #3차원에 스칼라 두개 행, 열 원소 개수\n",
    "# 3개의 변수에 3개의 wieght 3개의 weight를 랜덤으로 추출\n",
    "b=tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "def predict(X):\n",
    "    return tf.matmul(X,W)+b  #행렬 곱셈\n",
    "\n",
    "\n",
    "\n",
    "learning_rate=0.000001\n",
    "\n",
    "n_epochs = 2000\n",
    "\n",
    "for i in range(n_epochs+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean(tf.square(predict(X)-y))# squre 제곱근\n",
    "    \n",
    "    W_grad, b_grad = tape.gradient(cost,[W,b])\n",
    "    \n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 ==0 :\n",
    "        print(\"{:5} | {:10.4f}\".format(i,cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W=tf.Variable(tf.random.normal([3,1]))\n",
    "개별 인스턴스마다 출력이 되므로 1 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
