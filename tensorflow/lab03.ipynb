{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=np.array([1,2,3])\n",
    "Y=np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy 배열\n",
    "\n",
    "많은 숫자 데이터를 하나의 변수에 넣고 관리 할 때 리스트는 속도가 느리고 메모리를 많이 차지하는 단점이 있다. 배열(array)을 사용하면 적은 메모리로 데이터를 빠르게 처리할 수 있다. 배열은 리스트와 비슷하지만 다음과 같은 점에서 다르다.\n",
    "\n",
    "모든 원소가 같은 자료형이어야 한다.\n",
    "원소의 갯수를 바꿀 수 없다.\n",
    "파이썬은 자체적으로 배열 자료형을 제공하지 않는다. 따라서 배열을 구현한 다른 패키지를 임포트해야 한다. 파이썬에서 배열을 사용하기 위한 표준 패키지는 NumPy(보통 \"넘파이\"라고 발음한다)이다.\n",
    "\n",
    "NumPy는 수치해석용 파이썬 패키지이다. 다차원의 배열 자료구조 클래스인 ndarray 클래스를 지원하며 벡터와 행렬을 사용하는 선형대수 계산에 주로 사용된다. 내부적으로는 BLAS 라이브러리와 LAPACK 라이브러리를 사용하고 있으며 C로 구현된 CPython에서만 사용할 수 있다.\n",
    "\n",
    "NumPy의 배열 연산은 C로 구현된 내부 반복문을 사용하기 때문에 파이썬 반복문에 비해 속도가 빠르며 벡터화 연산(vectorized operation)을 이용하여 간단한 코드로도 복잡한 선형 대수 연산을 수행할 수 있다. 또한 배열 인덱싱(array indexing)을 사용한 질의(Query) 기능을 이용하여 간단한 코드로도 복잡한 수식을 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:  -3.000|   cost:  74.66667\n",
      "W:  -2.429|   cost:  54.85714\n",
      "W:  -1.857|   cost:  38.09524\n",
      "W:  -1.286|   cost:  24.38095\n",
      "W:  -0.714|   cost:  13.71429\n",
      "W:  -0.143|   cost:   6.09524\n",
      "W:   0.429|   cost:   1.52381\n",
      "W:   1.000|   cost:   0.00000\n",
      "W:   1.571|   cost:   1.52381\n",
      "W:   2.143|   cost:   6.09524\n",
      "W:   2.714|   cost:  13.71429\n",
      "W:   3.286|   cost:  24.38095\n",
      "W:   3.857|   cost:  38.09524\n",
      "W:   4.429|   cost:  54.85714\n",
      "W:   5.000|   cost:  74.66667\n"
     ]
    }
   ],
   "source": [
    "def cost_func(W,X,Y):\n",
    "    c=0\n",
    "    for i in range(len(X)):\n",
    "        c+=(W*X[i]-Y[i])**2\n",
    "    return c/len(X)\n",
    "for feed_W in np.linspace(-3,5,num=15):\n",
    "    curr_cost=cost_func(feed_W,X,Y)\n",
    "    print(\"W:  {:6.3f}| cost:{:10.5f}\".format(feed_W,curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:  -3.000| cost:  74.66667\n",
      "W:  -2.429| cost:  54.85714\n",
      "W:  -1.857| cost:  38.09524\n",
      "W:  -1.286| cost:  24.38095\n",
      "W:  -0.714| cost:  13.71429\n",
      "W:  -0.143| cost:   6.09524\n",
      "W:   0.429| cost:   1.52381\n",
      "W:   1.000| cost:   0.00000\n",
      "W:   1.571| cost:   1.52381\n",
      "W:   2.143| cost:   6.09524\n",
      "W:   2.714| cost:  13.71429\n",
      "W:   3.286| cost:  24.38095\n",
      "W:   3.857| cost:  38.09524\n",
      "W:   4.429| cost:  54.85714\n",
      "W:   5.000| cost:  74.66667\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "X=np.array([1,2,3])\n",
    "Y=np.array([1,2,3])\n",
    "def cost_func(W,X,Y):\n",
    "    hypothesis=X*W\n",
    "    return tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "W_values=np.linspace(-3,5,num=15)\n",
    "cost_values=[]\n",
    "for feed_W in W_values:\n",
    "    curr_cost = cost_func(feed_W,X,Y)\n",
    "    cost_values.append(curr_cost)\n",
    "    print(\"W:  {:6.3f}| cost:{:10.5f}\".format(feed_W,curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=3, shape=(), dtype=float64, numpy=74.66666666666667>, <tf.Tensor: id=7, shape=(), dtype=float64, numpy=54.85714285714287>, <tf.Tensor: id=11, shape=(), dtype=float64, numpy=38.095238095238095>, <tf.Tensor: id=15, shape=(), dtype=float64, numpy=24.380952380952383>, <tf.Tensor: id=19, shape=(), dtype=float64, numpy=13.714285714285717>, <tf.Tensor: id=23, shape=(), dtype=float64, numpy=6.095238095238099>, <tf.Tensor: id=27, shape=(), dtype=float64, numpy=1.5238095238095248>, <tf.Tensor: id=31, shape=(), dtype=float64, numpy=0.0>, <tf.Tensor: id=35, shape=(), dtype=float64, numpy=1.5238095238095226>, <tf.Tensor: id=39, shape=(), dtype=float64, numpy=6.0952380952380905>, <tf.Tensor: id=43, shape=(), dtype=float64, numpy=13.714285714285703>, <tf.Tensor: id=47, shape=(), dtype=float64, numpy=24.380952380952383>, <tf.Tensor: id=51, shape=(), dtype=float64, numpy=38.09523809523808>, <tf.Tensor: id=55, shape=(), dtype=float64, numpy=54.85714285714284>, <tf.Tensor: id=59, shape=(), dtype=float64, numpy=74.66666666666667>]\n"
     ]
    }
   ],
   "source": [
    "aplha=0.01\n",
    "gradient=tf.reduce_mean(tf.multiply(tf.multiply(W,X)-Y),X)\n",
    "descent=W-tf.multiply(alpha,gradient)\n",
    "W.assign(descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|18332.2188| 47.398293\n",
      "   10| 3855.3564| 22.638384\n",
      "   20|  810.9046| 11.283927\n",
      "   30|  170.6631|  6.076973\n",
      "   40|   36.0217|  3.689155\n",
      "   50|    7.7069|  2.594144\n",
      "   60|    1.7524|  2.091991\n",
      "   70|    0.5001|  1.861713\n",
      "   80|    0.2368|  1.756112\n",
      "   90|    0.1814|  1.707684\n",
      "  100|    0.1698|  1.685477\n",
      "  110|    0.1673|  1.675292\n",
      "  120|    0.1668|  1.670622\n",
      "  130|    0.1667|  1.668481\n",
      "  140|    0.1667|  1.667498\n",
      "  150|    0.1667|  1.667048\n",
      "  160|    0.1667|  1.666842\n",
      "  170|    0.1667|  1.666747\n",
      "  180|    0.1667|  1.666703\n",
      "  190|    0.1667|  1.666684\n",
      "  200|    0.1667|  1.666674\n",
      "  210|    0.1667|  1.666670\n",
      "  220|    0.1667|  1.666668\n",
      "  230|    0.1667|  1.666667\n",
      "  240|    0.1667|  1.666667\n",
      "  250|    0.1667|  1.666667\n",
      "  260|    0.1667|  1.666667\n",
      "  270|    0.1667|  1.666667\n",
      "  280|    0.1667|  1.666667\n",
      "  290|    0.1667|  1.666667\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "X=[1.,2.,3.,4.]\n",
    "Y=[1.,3.,5.,7.]\n",
    "\n",
    "W=tf.Variable(tf.compat.v1.random_normal([1],-100.,100.))\n",
    "# W = tf.Variable(tf.random.normal([1], -100, 100))    2 version\n",
    "for step in range(300):\n",
    "    hypothesis=X*W\n",
    "    cost=tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "    \n",
    "    alpha=0.01\n",
    "    gradient=tf.reduce_mean(tf.multiply(tf.multiply(W,X)-Y,X))\n",
    "    descent=W-tf.multiply(alpha,gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step%10==0:\n",
    "        print(f'{step:5}|{cost.numpy():10.4f}|{W.numpy()[0]:10.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |    83.5000 |    4.750000\n",
      "   10 |    17.6915 |    3.080629\n",
      "   20 |     3.8521 |    2.315085\n",
      "   30 |     0.9417 |    1.964020\n",
      "   40 |     0.3297 |    1.803027\n",
      "   50 |     0.2009 |    1.729199\n",
      "   60 |     0.1739 |    1.695343\n",
      "   70 |     0.1682 |    1.679817\n",
      "   80 |     0.1670 |    1.672697\n",
      "   90 |     0.1667 |    1.669432\n",
      "  100 |     0.1667 |    1.667935\n",
      "  110 |     0.1667 |    1.667248\n",
      "  120 |     0.1667 |    1.666933\n",
      "  130 |     0.1667 |    1.666789\n",
      "  140 |     0.1667 |    1.666723\n",
      "  150 |     0.1667 |    1.666692\n",
      "  160 |     0.1667 |    1.666678\n",
      "  170 |     0.1667 |    1.666672\n",
      "  180 |     0.1667 |    1.666669\n",
      "  190 |     0.1667 |    1.666668\n",
      "  200 |     0.1667 |    1.666667\n",
      "  210 |     0.1667 |    1.666667\n",
      "  220 |     0.1667 |    1.666667\n",
      "  230 |     0.1667 |    1.666667\n",
      "  240 |     0.1667 |    1.666667\n",
      "  250 |     0.1667 |    1.666667\n",
      "  260 |     0.1667 |    1.666667\n",
      "  270 |     0.1667 |    1.666667\n",
      "  280 |     0.1667 |    1.666667\n",
      "  290 |     0.1667 |    1.666667\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "X=[1.,2.,3.,4.]\n",
    "Y=[1.,3.,5.,7.]\n",
    "W=tf.Variable([5.])\n",
    "for step in range(300):\n",
    "    hypothesis=W*X\n",
    "    cost=tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "    \n",
    "    alpha=0.01\n",
    "    gradient=tf.reduce_mean(tf.multiply(tf.multiply(W,X)-Y,X))  #미분\n",
    "    descent=W-tf.multiply(alpha,gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step%10==0:\n",
    "#         print(f'{step:5}|{cost.numpy():10.4f}|{W.numpy()[0]:10.6f}')\n",
    "        print('{:5} | {:10.4f} |  {:10.6f}'.format(step,cost.numpy(),W.numpy()[0]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
